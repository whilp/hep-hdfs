<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
<property>
  <name>dfs.replication.max</name>
  <value>@HADOOP_REPLICATION_MAX@</value>
</property>
<property>
  <name>dfs.replication.min</name>
  <value>@HADOOP_REPLICATION_MIN@</value>
</property>
<property>
  <name>dfs.datanode.du.reserved</name>
  <value>10000000000</value>
</property>
<property>
  <name>dfs.balance.bandwidthPerSec</name>
  <value>2000000000</value>
</property>
<property>
  <name>dfs.data.dir</name>
  <value>@HADOOP_DATA@</value>
</property>
<property>
  <name>dfs.datanode.handler.count</name>
  <value>10</value>
</property>
<property>
  <name>dfs.hosts.exclude</name>
  <value>@HADOOP_CONF_DIR@/hosts_exclude</value>
</property>
<property>
  <name>dfs.namenode.handler.count</name>
  <value>40</value>
</property>
<property>
  <name>dfs.namenode.logging.level</name>
  <value>all</value>
</property>
<property>
  <name>fs.checkpoint.dir</name>
  <value>@HADOOP_CHECKPOINT_DIRS@</value>
</property>
<property>
  <name>topology.script.file.name</name>
  <value>@HADOOP_RACKAWARE_SCRIPT@</value>
</property>
<property>
  <name>dfs.secondary.http.address</name>
  <value>@HADOOP_SECONDARY_HTTP_ADDRESS@</value>
  <description>
    The secondary namenode http server address and port.
    If the port is 0 then the server will start on a free port.
  </description>
</property>
<property>
  <name>dfs.http.address</name>
  <value>@HADOOP_PRIMARY_HTTP_ADDRESS@</value>
  <description>
    The address and the base port where the dfs namenode web ui will listen on.
    If the port is 0 then the server will start on a free port.
  </description>
</property>
<property>
  <name>fs.checkpoint.period</name>
  <value>@HADOOP_CHECKPOINT_PERIOD@</value>
  <description>The number of seconds between two periodic checkpoints.
  </description>
</property>
</configuration>
